{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio-Exam Task 2 in MADS-DVVA (Data Visualization and Visual Analytics) - Data Retrieval\n",
    "\n",
    "## Data Source\n",
    "In this notebook I'm retrieving playlist tracks with the [Spotify API](https://developer.spotify.com/documentation/web-api). This notebook is structured as followed:\n",
    "\n",
    "1. Request an API key and save it in a file.\n",
    "\n",
    "2. Get the tracks of my friends spotify playlist. 1 playlist per friend\n",
    "\n",
    "3. Get further information about the tracks by requesting the features of the songs.\n",
    "\n",
    "4. Get information about the songs artists and genres\n",
    "\n",
    "5. Merge the 3 datasets and select interesting features.\n",
    "\n",
    "## You want it to run yourself?\n",
    "If you want to ran the data retrieval yourself then you need to follow these steps.\n",
    "\n",
    "1. Create an app to get an access token: https://developer.spotify.com/documentation/web-api/tutorials/getting-started\n",
    "\n",
    "2. Create a file called 'secred.json' and paste your secrets and id in the json. The structure can be accessed in the code below.\n",
    "\n",
    "3. Retrieve playlist data by pasting the [playlist id](https://clients.caster.fm/knowledgebase/110/How-to-find-Spotify-playlist-ID.html) in the necessary lists.Don't forget to change the naming of the file. You need to do that steps 2,3,4,5 at the end of the code blocks.\n",
    "\n",
    "4. Done!\n",
    "\n",
    "## Data Retrieval\n",
    "\n",
    "Import the used librarys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomruge/anaconda3/envs/env3.12.2/lib/python3.12/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Request an API key and save it in a file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access token obtained successfully:\n",
      "{'access_token': 'BQBzTwWo2aiJgnMr-V-hmoUMceC9_fzZ8Z4dUW1QSkRkA2uU2UOKWlgvuEebtmt16IJiTYPLvZF8nqZQ9qvgmtqhzloB8xul2aS6bs3Y1vjYe0Gxhyrusob7CFREIeyD', 'token_type': 'Bearer', 'expires_in': 3600, 'scope': 'playlist-read-private'}\n"
     ]
    }
   ],
   "source": [
    "def get_authorization_code() -> None:\n",
    "    \"\"\"\n",
    "    Fetches an authorization token from Spotify API using client credentials flow \n",
    "    and saves the access token to a file.\n",
    "    \"\"\"\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "\n",
    "    header = {\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "\n",
    "    # Read client_id and client_secret from json file\n",
    "    with open(\"secret.json\", \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        client_id = data[\"client_id\"]\n",
    "        client_secret = data[\"client_secret\"]\n",
    "\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"scope\": \"playlist-read-private\",\n",
    "        \"client_id\": client_id,  \n",
    "        \"client_secret\": client_secret \n",
    "    }\n",
    "\n",
    "    # Send POST request to Spotify API\n",
    "    response = requests.post(url, data=data, headers=header)\n",
    "\n",
    "    # Handle response\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        save_access_token(result)\n",
    "        print(\"Access token obtained successfully:\")\n",
    "        print(result)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "\n",
    "def save_access_token(response: Dict[str, str]) -> None:\n",
    "    \"\"\"\n",
    "    Saves the access token from the Spotify API response to a file.\n",
    "    \n",
    "    Args:\n",
    "    - response (dict): Response JSON object from Spotify API containing access token.\n",
    "    \"\"\"\n",
    "    access_token = response[\"access_token\"]\n",
    "    with open(\"access_token.txt\", \"w\") as file:\n",
    "        file.write(access_token)\n",
    "\n",
    "# Execute the function to obtain and save the access token\n",
    "get_authorization_code()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the Tracks of Playlists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpotifyPlaylistFetcher:\n",
    "    def __init__(self, playlist_id: str, access_token_file: str = \"access_token.txt\", \n",
    "                 offset: int = 0, limit: int = 100, save_name: str = 'response'):\n",
    "        \"\"\"\n",
    "        Initialize the SpotifyPlaylistFetcher instance.\n",
    "\n",
    "        Args:\n",
    "        - playlist_id (str): Spotify playlist ID.\n",
    "        - access_token_file (str): File containing Spotify API access token.\n",
    "        - offset (int): Offset for pagination (default is 0).\n",
    "        - limit (int): Limit for number of items per request (default is 100, max is 100).\n",
    "        - save_name (str): Name of the file to save the combined response (default is 'response').\n",
    "        \"\"\"\n",
    "        self.playlist_id = playlist_id\n",
    "        self.access_token_file = access_token_file\n",
    "        self.offset = offset\n",
    "        self.limit = limit\n",
    "        self.save_name = save_name\n",
    "        self.access_token = self._read_access_token()\n",
    "        self.headers = {'Authorization': f'Bearer {self.access_token}'}\n",
    "    \n",
    "    def _read_access_token(self) -> str:\n",
    "        \"\"\"\n",
    "        Read the Spotify API access token from a file.\n",
    "\n",
    "        Returns:\n",
    "        - str: Spotify API access token.\n",
    "        \"\"\"\n",
    "        with open(self.access_token_file, \"r\") as file:\n",
    "            return file.read().strip()\n",
    "    \n",
    "    def get_playlist_items(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetch all items (tracks) from the specified Spotify playlist.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: DataFrame containing all items (tracks) from the playlist.\n",
    "        \"\"\"\n",
    "        # Initialize lists to hold responses\n",
    "        responses_items = []\n",
    "        responses_hole = []\n",
    "        \n",
    "        # Make the first request\n",
    "        url = f\"https://api.spotify.com/v1/playlists/{self.playlist_id}/tracks?offset={self.offset}&limit={self.limit}\"\n",
    "        response = requests.get(url, headers=self.headers).json()\n",
    "        responses_items.append(self._get_items(response))\n",
    "        responses_hole.append(response)\n",
    "        \n",
    "        # Loop through next pages if they exist\n",
    "        while response.get(\"next\"):\n",
    "            self.offset += self.limit\n",
    "            next_url = response[\"next\"]\n",
    "            response = requests.get(next_url, headers=self.headers).json()\n",
    "            responses_items.append(self._get_items(response))\n",
    "\n",
    "        # Combine the responses\n",
    "        items = self._combine_items(responses_items)\n",
    "        \n",
    "        # Save the combined items\n",
    "        self._save_response(items)\n",
    "        \n",
    "        return items\n",
    "    \n",
    "    def _combine_items(self, responses_list: list) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Combine list of responses into a single DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - responses_list (list): List of JSON responses from Spotify API.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: Combined DataFrame containing all items (tracks) from responses.\n",
    "        \"\"\"\n",
    "        # Create a list of DataFrames from the JSON responses\n",
    "        items_list = [pd.json_normalize(response) for response in responses_list]\n",
    "        # Combine all DataFrames into a single DataFrame\n",
    "        items = pd.concat(items_list, ignore_index=True)\n",
    "        return items\n",
    "    \n",
    "    def _save_response(self, response: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Save DataFrame to a CSV file.\n",
    "\n",
    "        Args:\n",
    "        - response (pd.DataFrame): DataFrame to be saved.\n",
    "        \"\"\"\n",
    "        response.to_csv(self.save_name, index=False)\n",
    "    \n",
    "    def _get_items(self, response: dict) -> list:\n",
    "        \"\"\"\n",
    "        Extract items (tracks) from Spotify API response.\n",
    "\n",
    "        Args:\n",
    "        - response (dict): JSON response from Spotify API.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of items (tracks) from the response.\n",
    "        \"\"\"\n",
    "        return response.get(\"items\", [])\n",
    "\n",
    "# change playlist_ids and names to the ones you want to fetch\n",
    "playlist_ids = ['1b5wfP2ZAaNXEqLYEuo748', '4PK4fDXPX3Fi6puntDvxIG']\n",
    "names = ['lars.csv', 'marco.csv']\n",
    "\n",
    "for i in range(len(playlist_ids)):\n",
    "    fetcher = SpotifyPlaylistFetcher(playlist_ids[i], save_name=f\"data/{names[i]}\")\n",
    "    result = fetcher.get_playlist_items()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get further information about the tracks by requesting the features of the songs.\n",
    "\n",
    "The playlist request does not return much information about the tracks. We will use the following API: https://developer.spotify.com/documentation/web-api/reference/get-several-audio-features ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features(multiple_ids: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches audio features from Spotify API for multiple track IDs.\n",
    "\n",
    "    Args:\n",
    "    - multiple_ids (list): List of track IDs.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing audio features for the tracks.\n",
    "    \"\"\"\n",
    "    id_batches = [multiple_ids[i:i + 100] for i in range(0, len(multiple_ids), 100)]\n",
    "    access_token_file = \"access_token.txt\"\n",
    "    \n",
    "    with open(access_token_file, \"r\") as file:\n",
    "        token = file.read().strip()\n",
    "    \n",
    "    headers = {'Authorization': f'Bearer {token}'}\n",
    "    features = []\n",
    "    \n",
    "    for batch in id_batches:\n",
    "        url = \"https://api.spotify.com/v1/audio-features?ids=\" + ','.join(batch)\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            data = response.json()\n",
    "            features.extend(data['audio_features'])\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching audio features: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "def get_playlist_ids(path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts track IDs from a Spotify playlist CSV file.\n",
    "\n",
    "    Args:\n",
    "    - path (str): Path to the CSV file containing playlist data.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of track IDs extracted from the playlist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        ids = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            track_url = row.get('track.external_urls.spotify', '')\n",
    "            track_id = track_url.split('/')[-1] if track_url else None\n",
    "            if track_id:\n",
    "                ids.append(track_id)\n",
    "        \n",
    "        return ids\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File {path} not found.\")\n",
    "        return []\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: File {path} is empty.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def save_features(path: str, new_features: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Saves audio features DataFrame to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    - path (str): Path to the original playlist CSV file.\n",
    "    - new_features (pd.DataFrame): DataFrame containing audio features to be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        new_features.to_csv(path[:-4] + '_audio_features.csv', index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving features to file: {e}\")\n",
    "\n",
    "\n",
    "playlists = ['lars.csv', 'marco.csv']\n",
    "for playlist in playlists:\n",
    "    path = 'data/' + playlist\n",
    "    ids = get_playlist_ids(path)\n",
    "    features = get_audio_features(ids)\n",
    "    save_features(path, features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get Artists of Songs\n",
    "Previous requests did not contain usable infromation about the artists. Spotify does not provide information about the genre of a specific song. Only for the artist. We will assume that the songy by the artists are also in the artists genre. We will sue follwoing API for this: https://developer.spotify.com/documentation/web-api/reference/get-multiple-artists ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to decode JSON for row 54: Expecting ',' delimiter: line 1 column 209 (char 208)\n",
      "Failed to decode JSON for row 55: Expecting ',' delimiter: line 1 column 209 (char 208)\n",
      "Failed to decode JSON for row 56: Expecting ',' delimiter: line 1 column 209 (char 208)\n"
     ]
    }
   ],
   "source": [
    "def get_artists_from_playlist(name: str) -> List[List[str]]:\n",
    "    \"\"\"\n",
    "    Extracts artist IDs from a Spotify playlist CSV file.\n",
    "\n",
    "    Args:\n",
    "    - name (str): Path to the CSV file containing playlist data.\n",
    "\n",
    "    Returns:\n",
    "    - List[List[str]]: List of lists, where each sublist contains artist IDs for a track.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(name)\n",
    "    artists = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        artist = row['track.artists']\n",
    "        \n",
    "        # Replace single quotes used as delimiters with double quotes\n",
    "        artist = re.sub(r\"(?<!\\\\)'\", \"\\\"\", artist)\n",
    "        \n",
    "        try:\n",
    "            artist_list = json.loads(artist)\n",
    "            dummy = []\n",
    "            for a in artist_list:\n",
    "                dummy.append(a['id'])\n",
    "            artists.append(dummy)\n",
    "        except json.JSONDecodeError as e:\n",
    "            # give where the error is\n",
    "\n",
    "            print(f\"Failed to decode JSON for row {index}: {e}\")\n",
    "    \n",
    "    return artists\n",
    "\n",
    "\n",
    "def get_artist_info(multiple_ids: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches detailed information for artists from Spotify API based on their IDs.\n",
    "\n",
    "    Args:\n",
    "    - multiple_ids (List[str]): List of artist IDs.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing artists' information (name, genres, popularity).\n",
    "    \"\"\"\n",
    "    id_batches = [multiple_ids[i:i + 50] for i in range(0, len(multiple_ids), 50)]\n",
    "    access_token_file = \"access_token.txt\"\n",
    "    \n",
    "    with open(access_token_file, \"r\") as file:\n",
    "        token = file.read().strip()\n",
    "    \n",
    "    headers = {'Authorization': f'Bearer {token}'}\n",
    "    artist_df = pd.DataFrame()\n",
    "\n",
    "    for ids in id_batches:\n",
    "        url = \"https://api.spotify.com/v1/artists?ids=\" + ','.join(ids)\n",
    "        response = requests.get(url, headers=headers).json()\n",
    "        artists_info = response['artists']\n",
    "        artist_df = pd.concat([artist_df, pd.DataFrame(artists_info, columns=['name', 'genres', 'popularity'])], ignore_index=True, axis=0)\n",
    "    \n",
    "    return artist_df\n",
    "\n",
    "\n",
    "def get_nr_artists_per_song(artists: List[List[str]]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Computes the number of artists for each song in a playlist.\n",
    "\n",
    "    Args:\n",
    "    - artists (List[List[str]]): List of lists, where each sublist contains artist IDs for a track.\n",
    "\n",
    "    Returns:\n",
    "    - List[int]: List containing the number of artists per song.\n",
    "    \"\"\"\n",
    "    return [len(a) for a in artists]\n",
    "\n",
    "\n",
    "def flatten_list(l: List[List[str]]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Flattens a list of lists into a single list.\n",
    "\n",
    "    Args:\n",
    "    - l (List[List[str]]): List of lists to be flattened.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: Flattened list of strings.\n",
    "    \"\"\"\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "\n",
    "def unflatten_df(nr_artists_per_song: List[int], flattened_artists_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts a flattened DataFrame back into a structured DataFrame for songs.\n",
    "\n",
    "    Args:\n",
    "    - nr_artists_per_song (List[int]): List containing the number of artists per song.\n",
    "    - flattened_artists_df (pd.DataFrame): Flattened DataFrame containing artists' information.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with structured columns (names, genres, popularity) for each song.\n",
    "    \"\"\"\n",
    "    song_names = []\n",
    "    song_genres = []\n",
    "    song_popularity = []\n",
    "    beg_index = 0\n",
    "    \n",
    "    for nr in nr_artists_per_song:\n",
    "        end_index = beg_index + nr\n",
    "        sub_df = flattened_artists_df.iloc[beg_index:end_index]\n",
    "        \n",
    "        song_names.append(sub_df['name'].tolist())\n",
    "        song_genres.append(sub_df['genres'].tolist())\n",
    "        song_popularity.append(sub_df['popularity'].tolist())\n",
    "        \n",
    "        beg_index = end_index\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'names': song_names,\n",
    "        'genres': song_genres,\n",
    "        'popularity': song_popularity\n",
    "    })\n",
    "    \n",
    "    # Ensure 'genres' column is one-dimensional\n",
    "    result_df['genres'] = result_df['genres'].apply(lambda x: x[0] if x else None)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def fuse_dataframes(name: str, artists: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merges a DataFrame containing playlist data with a DataFrame containing artists' information.\n",
    "\n",
    "    Args:\n",
    "    - name (str): Path to the CSV file containing playlist data.\n",
    "    - artists (pd.DataFrame): DataFrame containing artists' information.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Merged DataFrame containing both playlist data and artists' information.\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(name)\n",
    "    return pd.concat([df1, artists], axis=1)\n",
    "\n",
    "def save_artist_info(artist_info: pd.DataFrame, name: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves DataFrame containing artists' information to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    - artist_info (pd.DataFrame): DataFrame containing artists' information.\n",
    "    - name (str): Path to save the CSV file.\n",
    "    \"\"\"\n",
    "    artist_info.to_csv(name, index=False)\n",
    "\n",
    "names = ['lars.csv', 'marco.csv']\n",
    "for name in names:\n",
    "    path = 'data/' + name\n",
    "    artists = get_artists_from_playlist(path)\n",
    "    nr_artists_per_song = get_nr_artists_per_song(artists)\n",
    "    flattened_artists = flatten_list(artists)\n",
    "    artist_info = get_artist_info(flattened_artists)\n",
    "    artists_correct_shape = unflatten_df(nr_artists_per_song, artist_info)\n",
    "    save_artist_info(artists_correct_shape, path[:-4] + '_artist_info.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows are not parsed properly. For example 'Guns N' Roses'. Because it contains ' in the name itself. This bug is not fixed since it does not have influence on the data analysis. This bug should be fixed in the future.\n",
    "\n",
    "## 5. Merging Datasets\n",
    "In the last step we will merge the datasets und select the iteresting features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(combined_dfs):\n",
    "    \"\"\"\n",
    "    Selects specific features (columns) from a combined DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - combined_dfs (pd.DataFrame): Combined DataFrame containing data from multiple sources.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame containing selected features.\n",
    "    \"\"\"\n",
    "    selected_features = [\n",
    "        'track.name', 'added_at',\n",
    "        'track.album.release_date', 'track.album.release_date_precision', 'danceability', \n",
    "        'energy', 'key', 'loudness',\n",
    "        'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "        'type', 'duration_ms', 'time_signature', 'uri',\n",
    "        'names', 'genres', 'popularity'\n",
    "    ]\n",
    "\n",
    "    selected_df = combined_dfs[selected_features]\n",
    "    return selected_df\n",
    "\n",
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    Renames columns in a DataFrame to make them more descriptive.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame to be modified.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with renamed columns.\n",
    "    \"\"\"\n",
    "    column_mapping = {\n",
    "        'track.name': 'track_name',\n",
    "        'track.album.release_date': 'release_date', \n",
    "        'track.album.release_date_precision': 'release_date_precision',\n",
    "        'danceability': 'danceability', \n",
    "        'energy': 'energy', \n",
    "        'key': 'key', \n",
    "        'loudness': 'loudness',\n",
    "        'mode': 'mode', \n",
    "        'speechiness': 'speechiness', \n",
    "        'acousticness': 'acousticness', \n",
    "        'instrumentalness': 'instrumentalness', \n",
    "        'liveness': 'liveness', \n",
    "        'valence': 'valence', \n",
    "        'tempo': 'tempo',\n",
    "        'type': 'type', \n",
    "        'uri': 'uri', \n",
    "        'duration_ms': 'duration_ms', \n",
    "        'time_signature': 'time_signature',\n",
    "        'names': 'artist_names', \n",
    "        'genres': 'artist_genres', \n",
    "        'popularity': 'artist_popularity'\n",
    "    }\n",
    "\n",
    "    return df.rename(columns=column_mapping)\n",
    "\n",
    "def concat_dfs(dfs):\n",
    "    \"\"\"\n",
    "    Concatenates multiple DataFrames horizontally (column-wise).\n",
    "\n",
    "    Args:\n",
    "    - dfs (list of pd.DataFrame): List of DataFrames to be concatenated.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "def save_df(df, name):\n",
    "    \"\"\"\n",
    "    Saves a DataFrame to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame to be saved.\n",
    "    - name (str): Name of the CSV file to save.\n",
    "    \"\"\"\n",
    "    df.to_csv(name, index=False)\n",
    "\n",
    "\n",
    "files = [['data/lars.csv', 'data/lars_audio_features.csv', 'data/lars_artist_info.csv'],\n",
    "             ['data/marco.csv', 'data/marco_audio_features.csv', 'data/marco_artist_info.csv']]\n",
    "for file in files:\n",
    "    dfs = [pd.read_csv(one_file) for one_file in file]\n",
    "    combined_df = concat_dfs(dfs)\n",
    "    selected_df = select_features(combined_df)\n",
    "    selected_df = rename_columns(selected_df)\n",
    "    save_df(selected_df, file[0][:-4] + '_combined.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Assistance\n",
    "\n",
    "- **Github Copilot**: Version 1.206.0.0\n",
    "\n",
    "- **ChatGPT**: Version  3.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
